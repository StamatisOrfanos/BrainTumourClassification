{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom CNN model for Brain Tumour Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# hyper-parameters\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "# Base Path\n",
    "BASE_PATH = 'archive/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up GPU growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a basic CNN model to try classify the data\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        # Max pooling layer\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(32 * 56 * 56, 10)  # Modify the output size based on your task\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor for the fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data for the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformer function to create the data-set for the training\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Transform data to Tensor object to load to CNN model\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]),\n",
    "    'test':  transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "}\n",
    "\n",
    "\n",
    "# Load the training and testing dataset \n",
    "image_datasets = {\n",
    "    'train': torchvision.datasets.ImageFolder(BASE_PATH + 'Training', data_transforms['train']),\n",
    "    'test':  torchvision.datasets.ImageFolder(BASE_PATH + 'Testing',  data_transforms['test'])\n",
    "}\n",
    "\n",
    "# Create the Dataloader object \n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=128,shuffle=True),\n",
    "    'test' : torch.utils.data.DataLoader(image_datasets['test'],  batch_size=32, shuffle=False)  \n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = MyCNN().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training procedure\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return running_loss / len(dataloader), accuracy\n",
    "\n",
    "# Define the testing procedure\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    test_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predictions.extend(predicted.tolist())\n",
    "            true_labels.extend(labels.tolist())\n",
    "            test_outputs.append(outputs)  # Move to CPU\n",
    "\n",
    "    test_outputs = torch.cat(test_outputs, dim=0)  # Concatenate the outputs tensor\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    test_loss = criterion(test_outputs, torch.tensor(true_labels).to(device))\n",
    "\n",
    "    return accuracy, precision, recall, test_loss, true_labels, predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25\n",
      "Train Loss: 1.3461 - Train Accuracy: 0.4804\n",
      "Epoch: 2/25\n",
      "Train Loss: 0.8146 - Train Accuracy: 0.6884\n",
      "Epoch: 3/25\n",
      "Train Loss: 0.6613 - Train Accuracy: 0.7502\n",
      "Epoch: 4/25\n",
      "Train Loss: 0.6150 - Train Accuracy: 0.7659\n",
      "Epoch: 5/25\n",
      "Train Loss: 0.5536 - Train Accuracy: 0.7981\n",
      "Epoch: 6/25\n",
      "Train Loss: 0.5214 - Train Accuracy: 0.8109\n",
      "Epoch: 7/25\n",
      "Train Loss: 0.4899 - Train Accuracy: 0.8246\n",
      "Epoch: 8/25\n",
      "Train Loss: 0.4508 - Train Accuracy: 0.8447\n",
      "Epoch: 9/25\n",
      "Train Loss: 0.4279 - Train Accuracy: 0.8480\n",
      "Epoch: 10/25\n",
      "Train Loss: 0.4052 - Train Accuracy: 0.8589\n",
      "Epoch: 11/25\n",
      "Train Loss: 0.3782 - Train Accuracy: 0.8683\n",
      "Epoch: 12/25\n",
      "Train Loss: 0.3614 - Train Accuracy: 0.8750\n",
      "Epoch: 13/25\n",
      "Train Loss: 0.3520 - Train Accuracy: 0.8750\n",
      "Epoch: 14/25\n",
      "Train Loss: 0.3243 - Train Accuracy: 0.8871\n",
      "Epoch: 15/25\n",
      "Train Loss: 0.3384 - Train Accuracy: 0.8806\n",
      "Epoch: 16/25\n",
      "Train Loss: 0.3394 - Train Accuracy: 0.8741\n",
      "Epoch: 17/25\n",
      "Train Loss: 0.3102 - Train Accuracy: 0.8883\n",
      "Epoch: 18/25\n",
      "Train Loss: 0.2859 - Train Accuracy: 0.8978\n",
      "Epoch: 19/25\n",
      "Train Loss: 0.2736 - Train Accuracy: 0.9049\n",
      "Epoch: 20/25\n",
      "Train Loss: 0.3067 - Train Accuracy: 0.8817\n",
      "Epoch: 21/25\n",
      "Train Loss: 0.2850 - Train Accuracy: 0.9006\n",
      "Epoch: 22/25\n",
      "Train Loss: 0.2613 - Train Accuracy: 0.9081\n",
      "Epoch: 23/25\n",
      "Train Loss: 0.2367 - Train Accuracy: 0.9181\n",
      "Epoch: 24/25\n",
      "Train Loss: 0.2224 - Train Accuracy: 0.9205\n",
      "Epoch: 25/25\n",
      "Train Loss: 0.2540 - Train Accuracy: 0.9051\n"
     ]
    }
   ],
   "source": [
    "file_training = open('train_cnn.txt', 'a')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_accuracy = train(model, dataloaders['train'], criterion, optimizer, device)\n",
    "    print(f\"Epoch: {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f}\")\n",
    "    file_training.write('Epoch: {}/{} '.format(epoch+1, EPOCHS) + 'Train Loss: {0} - Train Accuracy: {1} '.format(train_loss, train_accuracy) + '\\n' )\n",
    "\n",
    "finish_time = time.time()\n",
    "\n",
    "file_training.write('Time needed to train for {0} epochs is: {1}'.format(EPOCHS, finish_time-start_time))\n",
    "file_training.close()\n",
    "torch.save(model.state_dict(), 'model-cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[230  62   2   6]\n",
      " [ 16 255  26   9]\n",
      " [  1   8 396   0]\n",
      " [  4  16   2 278]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.83       300\n",
      "           1       0.75      0.83      0.79       306\n",
      "           2       0.93      0.98      0.95       405\n",
      "           3       0.95      0.93      0.94       300\n",
      "\n",
      "    accuracy                           0.88      1311\n",
      "   macro avg       0.89      0.88      0.88      1311\n",
      "weighted avg       0.89      0.88      0.88      1311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model and evaluate the it on the test data\n",
    "test_file = open('test_cnn.txt', 'a')\n",
    "loaded_model = MyCNN()\n",
    "loaded_model.load_state_dict(torch.load('model-cnn.pth'))\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# Calculate confusion matrix\n",
    "test_accuracy, test_precision, test_recall, test_loss, test_true_labels, test_predictions = evaluate(model, dataloaders['test'], criterion, device)\n",
    "\n",
    "# Calculate Confusion Matrix\n",
    "confusion_mtx = confusion_matrix(test_true_labels, test_predictions)\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)\n",
    "test_file.write('Confusion Matrix:\\n{}\\n'.format(confusion_mtx))\n",
    "\n",
    "# Calculate Classification Report\n",
    "class_report = classification_report(test_true_labels, test_predictions)\n",
    "\n",
    "# Print Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "test_file.write('Classification Report:\\n{}\\n'.format(class_report))\n",
    "test_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
