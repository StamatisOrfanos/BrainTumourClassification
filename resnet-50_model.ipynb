{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet-50 Model Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "# Import libraries\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# hyper-parameters\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Base Path\n",
    "BASE_PATH = 'archive/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import train/test datesets and use transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to Tensor object to load to Resnet model\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]),\n",
    "    'test':  transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "}\n",
    "\n",
    "\n",
    "# Load the training and testing dataset \n",
    "image_datasets = {\n",
    "    'train': torchvision.datasets.ImageFolder(BASE_PATH + 'Training', data_transforms['train']),\n",
    "    'test':  torchvision.datasets.ImageFolder(BASE_PATH + 'Testing',  data_transforms['test'])\n",
    "}\n",
    "\n",
    "# Create the Dataloader object \n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=128,shuffle=True),\n",
    "    'test' : torch.utils.data.DataLoader(image_datasets['test'],  batch_size=32, shuffle=False)  \n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Resnet-50 Model\n",
    "\n",
    "We use transfer learning in order to train the latest layer of a Resnet model in order to get a baseline of the performance for the state-of-art image classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from transformers library\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Define the number of features we are going to training in this project, which are the last layers parameters\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, len(image_datasets['train'].classes))\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# Define the loss function and the optimizer function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training and testing procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train procedure for the model\n",
    "def train(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return running_loss, accuracy\n",
    "\n",
    "\n",
    "# Define the test/evaluation procedure for the model\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(inputs)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "\n",
    "            predictions.extend(predicted.tolist())\n",
    "            true_labels.extend(labels.tolist())\n",
    "            outputs.extend(output.tolist())\n",
    "\n",
    "    return predictions, true_labels, outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with the training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_training = open('train_resnet-50.txt', 'a')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_accuracy = train(model, dataloaders['train'], criterion, optimizer)  \n",
    "    print(f\"Epoch: {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f}\")\n",
    "    file_training.write('Epoch: {}/{} '.format(epoch+1, EPOCHS) + 'Train Loss: {0} - Train Accuracy: {1} '.format(train_loss, train_accuracy) + '\\n' )\n",
    "\n",
    "finish_time = time.time()\n",
    "\n",
    "file_training.write('Time needed to train for {0} epochs is: {1}'.format(EPOCHS, finish_time-start_time))\n",
    "file_training.close()\n",
    "torch.save(model.state_dict(), 'model-50.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the a custom Resnet-50 model that fits our problem of 4 classes\n",
    "class CustomResnet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomResnet, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=False)\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def load_backbone_weights(self, state_dict):\n",
    "        self.resnet.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the test file \n",
    "new_model =  CustomResnet(len(image_datasets['train'].classes))\n",
    "new_model.load_backbone_weights(torch.load('model-50.pth'))\n",
    "new_model = new_model.to(device)\n",
    "new_model.eval()\n",
    "test_file = open('test_resnet-50.txt', 'a+')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    test_predictions, test_true_labels, test_outputs = evaluate(new_model, dataloaders['test'])\n",
    "    test_predictions = torch.tensor(test_predictions, dtype=torch.long).to(device)  # Convert to Long\n",
    "    test_loss = criterion(torch.tensor(test_outputs).to(device), torch.tensor(test_true_labels).to(device))\n",
    "    \n",
    "    test_predictions_list = test_predictions.tolist()\n",
    "    test_true_labels_list = test_true_labels\n",
    "\n",
    "    test_accuracy = sum([1 for i, j in zip(test_predictions_list, test_true_labels_list) if i == j]) / len(test_predictions_list)\n",
    "  \n",
    "    print(f\"Epoch: {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.4f}\")\n",
    "    test_file.write('Epoch: {}/{} '.format(epoch+1, EPOCHS) + 'Test Loss: {0} - Test Accuracy: {1} '.format(test_loss, test_accuracy) + '\\n')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "test_predictions, test_true_labels, outputs = evaluate(new_model, dataloaders['test'])\n",
    "confusion_mtx = confusion_matrix(test_true_labels, test_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)\n",
    "test_file.write('Confusion Matrix: \\n{}\\n'.format(confusion_matrix))\n",
    "\n",
    "# Calculate classification report\n",
    "classification_rep = classification_report(test_true_labels, test_predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "test_file.write('Classification Matrix: \\n{}'.format(classification_rep))\n",
    "test_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
